# -*- coding: utf-8 -*-
"""2. 판다스.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JOZZSA3Z-DGojgZShJ8wmQ--PMWFeAnb

# **1. 판다스(Pandas)**
* 데이터 분석을 위한 파이썬 라이브러리 중 하나로, 표 형태의 데이터나 다양한 형태의 데이터를 쉽게 처리하고 분석
* 데이터프레임(DataFrame)이라는 자료구조를 제공
"""

!pip install pandas

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

"""# **2. Series와 DataFrame**

### 2-1. Series
* Series는 1차원 배열과 같은 자료구조로 하나의 열을 나타냄
* Series의 각 요소는 인덱스(index)와 값(value)으로 구성되어 있음
* 값은 넘파이의 ndarray 기반으로 저장됨
* Series는 다양한 데이터 타입을 가질 수 있으며, 정수, 실수, 문자열 등 다양한 형태의 데이터를 담을 수 있음
"""

idx = ['유민콩', '정현콩', '수현콩', '유현콩', '유선콩']
data = [100, 95, 80, 55, 60]

# pd.Series(데이터, 인덱스(생략가능) ...)
pd.Series(data)

se1 = pd.Series(data, idx)
se1

print(se1.index)
print(se1.values)

"""### 2-2. DataFrame
* 데이터프레임은 판다스 라이브러리에서 제공하는 중요하고 강력한 데이터 구조로, 엑셀과 유사한 2차원의 테이블 형태 데이터를 다룸
* 데이터프레임의 요소는 인덱스(index), 열(column), 값(value)
* 데이터프레임은 행과 열로 이루어져 있으며, 각 열은 다양한 데이터 타입을 가질 수 있음
* 값은 넘파이의 ndarray 기반으로 저장
"""

data = [[67, 93, 91],
        [75, 68, 96],
        [87, 81, 82],
        [62, 70, 75],
        [98, 56, 87]]

idx = ['유민콩', '정현콩', '수현콩', '유현콩', '유선콩']
col = ['국어', '영어', '수학']

# pd.DataFrame(데이터, 인덱스, 컬럼, ...)
pd.DataFrame(data)

pd.DataFrame(data, idx)

pd.DataFrame(data, idx, col)

df = pd.DataFrame(index = idx, columns = col, data = data)
df

print(df.index)
print(df.columns)
print(df.values)

"""### 2-3. 딕셔너리를 사용하여 데이터프레임 생성하기

"""

dic = {
    '국어':[67, 75, 87, 62, 98],
    '영어':[93, 68, 81, 70, 56],
    '수학':[91, 96, 82, 75, 87]
}

df = pd.DataFrame(data=dic, index=idx)
df

"""# **3. CSV 파일 읽어오기**
* csv(Comma Seperated Value)의 약자로, 데이터를 쉼표로 구분한 파일
"""

df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol.csv')
df

type(df)

"""# **4. 데이터프레임 기본정보 알아보기**"""

# info(): 행(row), 열(colums)의 기본적인 정보와 데이터 타입을 반환
df.info()

# 컬럼명 변경하기
print(df.columns)

new_columns = ['name', 'group', 'company', 'gender', 'birthday', 'height', 'blood', 'brand']
df.columns = new_columns
df

# describe(): 통계 정보를 반환
df.describe()

df.describe(include=object) # top:최빈값  freq: 최빈값의 빈도

# 원하는 개수의 데이터 보기
df.head()

df.head(3) # 3개

df.tail() # 하위 5개

# 정렬
df.sort_index() # index로 오름차순 정렬(기본값)

df.sort_index(ascending=False) # index로 내림차순 정렬

df.sort_values(by='height') # 키로 오름차순 정렬

df.sort_values(by='height', ascending=False) # 키로 내림차순 정렬

df.sort_values(by='height', ascending=False, na_position='first') # nan값 젤 위로 올리기

# 1차 저렬: 키(내림차순), 2차 정렬: 브랜드(내림차순)
df.sort_values(by=['height', 'brand'], ascending=[False, False])

"""# **데이터 다루기**"""

df.head()

df['blood']

type(df['blood'])

df.blood

df.head(3)

df[:3]

# loc 인덱싱: 컬럼 인덱싱, 행과 열 모두 인덱싱과 슬라이싱이 가능
df.loc[:, 'name'] # 행 다 가져오고 이름 열만

df.loc[2:5, 'name'] # 2행부터 5행(포함)

df.loc[2:5, ['name', 'gender', 'height']] # 2행부터 5행(포함)

df.loc[[2,5], 'name':'gender']

# iloc 인덱싱: index로 인덱싱. 행과 열 모두 인덱싱과 슬라이싱이 가능
df.iloc[:, 0]

df.iloc[:, [0,2]]

df.iloc[:, 0:2] # 2번 컬럼 포함 X

df.iloc[1:5, 0:2]

df['height'] >= 180

df[df['height'] >= 180]

df[df['height'] >= 180]['name'] # 앞 뒤 순서 바꿀 수 있음

df[df['height'] >= 180][['name', 'gender']]

"""### 문제
* 키가 170cm 이상인 연예인의 이름, 성별, 브랜드 데이터를 출력
* 단, loc를 사용
"""

df.loc[df['height'] >= 170, ['name', 'gender', 'brand']]

# isin(): 정의한 리스트에 있는 데이터를 불린으로 반환

company = ['빅히트', '어도어']
df['company'].isin(company)

df[df['company'].isin(company)]

"""# **6. 결측값(Null, NaN)**
* 비어있는 값, 판다스에서는 NaN(Not a number)로 표기한 것은 모두 결측값으로 취급
"""

df.info()

df.isna()

df[df['height'].isna()]

df[df['height'].notnull()]

"""### 문제
* 회사가 존재하는 연예인의 이름, 회사, 그룹, 성별의 데이터를 출력
* 단, loc를 사용
"""

df.loc[df['company'].notnull(), ['name', 'company', 'group', 'gender']]

# fillna(): 결측값을 채워주는 함수
df['height'].fillna(0) # df['height'].fillna(0, inplace=True)

df_copy = df.copy()
df_copy

height = df_copy['height'].mean()
height

df_copy['height'] = df_copy['height'].fillna(height)
df_copy

df_copy = df.copy()
df_copy

height = df_copy['height'].median() # 50% 값, 중위
height

df_copy['height'] = df_copy['height'].fillna(height)
df_copy

df_copy = df.copy()
df_copy

# dropna(): 결측값이 있는 행 또는 열 제거. 결측값이 한 개라도 있는 경우 삭제
df_copy.dropna() # axis=0: 행 삭제. 기본값

df_copy.dropna(axis=1) # 결측값 있는 열 제거

"""# **7. 행, 열 추가 및 삭제하기**
* 행을 추가할 때 dict 형태의 데이터를 만들고 append() 메서드를 사용하ㅕ 데이터를 추가
* ignore_inex = True 옵션을 추가해야 에러가 발생하지 않음
"""

df_copy = df.copy()
df_copy

dic = {
    'name':'유민콩',
    'group':'콩',
    'company':'우유조아',
    'gender':'여자',
    'birthday':'2020-02-02',
    'height':140,
    'blood':'A',
    'brand':1234567
}

# concat(): 데이터를 합침. axis=0 (기본)
df = pd.concat([df_copy, pd.DataFrame(dic, index=[0])], ignore_index=True)
df

"""### 문제
* nation이라는 열을 추가하고, nation에 모든 데이터는 '대한민국'이라고 저장
* 단, '유민콩'의 국적을 미국으로 변경하고 loc를 사용하여 출력
"""

df['nation'] = '대한민국'
df

df.loc[df['name'] == '유민콩', 'nation'] = '미국'

df

# 행 제거
df.drop(20, axis=0) # 20번 행 제거

df.tail() # 제거는 안됨

df.drop([1, 3, 5, 7, 20], axis=0)
df

df.drop('nation', axis=1)
df

df.drop(['group', 'nation'], axis=1)
df

"""# **8. 통계함수**"""

df.describe()

df['height'].sum() # 합계

df['height'].count() # 결측 제외 개수

df['height'].mean() # 평균

df['height'].median() # 중위

df['height'].max() # 최대값

df['height'].min() # 최소값

df['height'].var() # 분산

df['height'].std() # 표준편차

"""# **9. 그룹**"""

# groupby(): 데이터를 그룹으로 묶어서 분석할 때 사용
df.groupby('group')

# 그룹을 맺으면 통계함수를 사용할 수 있음
df.groupby('group').count()

df.groupby('group').mean(numeric_only=True)

df.groupby('group').sum(numeric_only=True)

df.groupby('gender').mean(numeric_only=True)

df.groupby('gender').mean(['height', 'brand'])

"""### 문제
* 혈액형별로 그룹을 맺고, 성별로 또 그룹을 나눈 후 키의 평균갑에 대한 데이터를 출력
"""

df.groupby(['blood', 'gender'])['height'].mean()

"""# **10. 중복값 제거하기**"""

# drop_uplicates(): 중복된 데이터를 제거
df['blood'].drop_duplicates()

df['blood'].drop_duplicates(keep='last')

# value_counts(): 열의 각 값에 대한 데이터의 개수를 반환. NaN은 생략
df['blood'].value_counts()

df['company'].value_counts()

df['company'].value_counts(dropna=False)

"""# **11. 데이터프레임 합치기**"""

df1 = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol.csv')
df2 = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol2.csv')

df1

df2

df_copy = df1.copy()

pd.concat([df1, df_copy]) # axis=0 (기본값)

# reset_index(): index를 새롭게 적용
df_concat = pd.concat([df1, df_copy])
df_concat.reset_index() # 기존의 인덱스가 index컬럼으로 추가됨

df_concat.reset_index(drop=True) # 기존의 인덱스 제거

pd.concat([df1, df2], axis=1) # 같은 index끼리 결합

df3 = df2.drop([1, 3, 5, 7])
df3

pd.concat([df1, df3], axis=1)

df_right = df2.drop([1, 3, 5, 7, 9], axis=0)
df_right

# 1, 3, 5, 7, 9 행 제거 후 인덱스 리셋
df_right = df_right.reset_index(drop=True)
df_right

dic = {
    '이름':'유민콩',
    '연봉':6000,
    '가족수':10
}

df_right = pd.concat([df_right, pd.DataFrame(dic, index=[0])], ignore_index=True)
df_right

# 합쳐보기
pd.concat([df1, df_right], axis=1)

# merge(): 특정 고유한 키(unique, id)값을 기준으로 합침
# merge(데이터프레임1, 데이터프레임2, on='유니크값', how='병합 기준')
# 병합의 기준: left, right, inner. cross
pd.merge(df1, df_right, on='이름', how='left') # 이름을 기준으로 합치고, 왼쪽의 데이터(df1)의 개수에 맞게 출력

pd.merge(df1, df_right, on='이름', how='right')

pd.merge(df1, df_right, on='이름', how='inner') # 이름을 기준으로 교집합

pd.merge(df1, df_right, how='cross') # 모든 경우의 수

df_right.columns = ['성함', '연봉', '가족수']
df_right

# pd.merge(df1, df_right, on='이름', how='right')
# KeyError: '이름'

pd.merge(df1, df_right, left_on='이름', right_on='성함', how='right')

"""# **12. 등수 매기기**"""

# rank(): 데이터프레임 또는 시리즈의 순위를 매기는 함수. 기본값은 ascending
df1['브랜드순위'] = df1['브랜드평판지수'].rank()
df1

df1['브랜드순위'] = df1['브랜드평판지수'].rank(ascending=False)
df1

# astype(): 특정열의 자료형을 변경
df1['브랜드순위'] = df1['브랜드평판지수'].rank(ascending=False).astype('int')
df1

"""# **13. 날짜 타입 사용하기**"""

df.info()

df['birthday']

# to_datetime(): object타입에서 datetime타입으로 변경
df['birthday'] = pd.to_datetime(df['birthday'])
df['birthday']

print(type(df['birthday']))
print(df['birthday'].dtypes)

df['birthday'].dt.year # 연도만 출력

df['birthday'].dt.month # 월만 출력

df['birthday'].dt.day # 일만 출력

df['birthday'].dt.hour # 시간만 출력

df['birthday'].dt.minute # 분만 출력

df['birthday'].dt.second # 초만 출력

df['birthday'].dt.dayofweek # 요일(0:월, 6:일)

df['birthday'].dt.isocalendar().week # 주차

"""# **14. apply 사용하기**
* Series나 DataFrame에 구체적인 로직을 적용하고 싶을 때 사용
* apply를 적용하기 위해서는 별도의 함수를 먼저 정의해야 함
* 작성된 함수를 apply에 매개변수로 전달함
* 콜백함수
"""

df.head()

# 성별을 남자는 1 여자는 0으로 변환(loc 사용)
df.loc[df['gender'] == '남자', 'gender'] = 1
df.loc[df['gender'] == '여자', 'gender'] = 0
df.head()

df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol.csv')
df

def male_or_female(x):
  if x == '남자':
    return 1
  elif x == '여자':
    return 0
  else:
    return None

df['성별'].apply(male_or_female) # 모든 행에 함수 적용됨

# 람다형으로
df['성별'].apply(lambda x: 1 if x == '남자' else 0)

df['new성별'] = df['성별'].apply(lambda x: 1 if x == '남자' else 0) # 파생변수로 추가
df.head()

"""# **15. map 사용하기**
* 딕셔너리를 통해 데이터와 같은 키의 값을 적용
"""

df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol.csv')
df

map_gender = {
    '남자':1,
    '여자':0
}

df['성별'].map(map_gender)

df['new성별'] = df['성별'].map(map_gender)
df

"""# **16. 데이터프레임의 산술연산**"""

df = pd.DataFrame({
    '파이썬':[60, 70, 80, 90, 95],
    '데이터분석':[40, 60, 70, 55, 87],
    '머신러닝딥러닝':[35, 40, 30, 70, 55]
})

df

print(df['파이썬'].dtypes)
print(type(df['파이썬']))

df['파이썬'] + df['데이터분석'] + df['머신러닝딥러닝']

# df에 총점, 평균이라는 파생변수를 만들고 파생변수에 총점, 평균을 구해서 저장
df['총점'] = df['파이썬'] + df['데이터분석'] + df['머신러닝딥러닝']
df['평균'] = df['총점'] / 3
df

df['파이썬'].sum() # df['파이썬'].sum(axis=0)

df['파이썬'].mean() # df['파이썬'].mean(axis=0)

df.sum()

df.mean()

df1 = pd.DataFrame({
    '파이썬':[60, 70, 80, 90, 95],
    '데이터분석':[40, 60, 70, 55, 87],
    '머신러닝딥러닝':[35, 40, 30, 70, 55]
})

df2 = pd.DataFrame({
    '파이썬':['C', 'B', 'B', 'A', 'A'],
    '데이터분석':[40, 60, 70, 55, 87],
    '머신러닝딥러닝':[35, 40, 30, 70, 55]
})

# df1 + df2
# TypeError: unsupported operand type(s) for +: 'int' and 'str'

df1 + 10

# df2 + 10
# TypeError: can only concatenate str (not "int") to str

df1 = pd.DataFrame({
    '데이터분석':[40, 60, 70, 55, 87],
    '머신러닝딥러닝':[35, 40, 30, 70, 55]
})

df2 = pd.DataFrame({
    '데이터분석':[40, 60, 70, 55],
    '머신러닝딥러닝':[35, 40, 30, 70]
})

df1 + df2 # 행의 개수가 빠진 경우 데이터를 nan으로 취급하기 때문에 결과도 nan
# 파이썬은 nan과 더하면 무조건 nan

"""# **17. select_dtypes**"""

df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/idol.csv')
df

df.info()

df.select_dtypes(include='object') # 문자열 컬럼만 가져오기

df.select_dtypes(exclude='object') # 문자열 컬럼만 빼고 가져오기

# 문자가 아닌 컬럼에만 10을 더함
df.select_dtypes(exclude='object')+10

# 문자열을 가지고 있는 컬럼의 이름만 변수에 저장하여 출력

object_names = df.select_dtypes(include=object).columns
object_names

df[object_names]

"""# **18. 원 핫 인코딩(One Hot Encoding)**
* 원 핫 인코딩은 한개의 요소는 1, 나머지 요소는 0으로 만들어 카테고리형을 표현하는 방법
* 예: df['혈액형']
  * 머신러닝/딥러닝 알고리즘에 넣어 데이터를 예측하려고 한다면 라벨 인코딩을 하여 수치 데이터로 변환
  * 컴퓨터는 값의 관계를 스스로 형성하게 될 수 있음
  * 만약 B형을1. AB형이 2라는 값을 가지고 있다면. 컴퓨터는 'B형 + AB형 = O형'이라는 이상한 관계를 맺을 수 있음
  * 따라서 별도의 column들을 형성해주고 1개의 column에는 1, 나머지 column에는 0으로 넣어줌으로 'A, B, AB, O형의 관계는 서로 독립적이다'라는 카테고리로 표현하는 방식
"""

blood_map = {'A':0, 'B':1, 'AB':2, 'O':3}
df['혈액형_code'] = df['혈액형'].map(blood_map) # 라벨 인코딩
df.head()

pd.get_dummies(df['혈액형_code'])

pd.get_dummies(df['혈액형'])



df = pd.get_dummies(df, columns=['혈액형'])
df

